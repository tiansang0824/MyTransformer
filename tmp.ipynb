{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 嵌入层",
   "id": "2a87b90dbdd18d7e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-03T12:44:36.216500Z",
     "start_time": "2024-08-03T12:44:34.113641Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T12:51:45.481853Z",
     "start_time": "2024-08-03T12:51:45.468385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [1,2,3,4],\n",
    "        [2,3,3,4]\n",
    "    ]\n",
    ")\n",
    "a.shape"
   ],
   "id": "ee03b13e1055af05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "创建嵌入层\n",
    "\n",
    "Embedding层用于将一个输入内容转化为一个向量.\n",
    "\n",
    "- 嵌入层的第一个参数是词汇表的长度,也就是所有词汇的总数量.\n",
    "\n",
    "    例如,假设a,b,c,d都是词汇,那么`a,b,b,c,c,d`中,一共有四个词汇,词汇表总长就是4.(因为4个长度足以覆盖全部内容)\n",
    "\n",
    "    在计算中,为每一个词汇分配一个独有的编号,例如,上述的内容就可以表示为[0,1,1,2,2,3]\n",
    "\n",
    "- 第二个参数是向量的维度.这里暂定24维\n",
    "\n"
   ],
   "id": "617501aba3441686"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T12:52:01.920268Z",
     "start_time": "2024-08-03T12:52:01.915917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建嵌入层\n",
    "ebd = nn.Embedding(5, 24)\n"
   ],
   "id": "59aeb295b1817a06",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T12:53:00.882959Z",
     "start_time": "2024-08-03T12:53:00.874612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bbb = ebd(a)\n",
    "print(f'bbb:\\n{bbb}\\nbbb.shape=\\n{bbb.shape}')"
   ],
   "id": "59ea4875fe261506",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbb:\n",
      "tensor([[[-0.5001, -2.2255,  2.3164,  0.2454,  0.3520, -1.8837, -0.2393,\n",
      "          -0.8723, -0.3934,  0.7691, -1.3037, -0.9851, -2.7072, -0.1381,\n",
      "           0.7716,  1.3942, -1.8074,  1.1158,  0.5645, -0.0141, -1.3274,\n",
      "          -1.8499,  0.3350,  0.4538],\n",
      "         [ 0.5651,  3.4911, -0.9449, -0.8897, -1.7088, -0.1747, -0.1165,\n",
      "           0.2865, -0.9496,  0.9583, -1.1354,  1.3982, -0.5795, -0.3252,\n",
      "           1.0468,  0.1211,  0.2555, -0.4093,  0.0700, -0.5264,  1.0216,\n",
      "           0.2576, -0.3247,  1.4577],\n",
      "         [-1.2724, -0.4139,  1.8491,  0.4949, -0.5004, -0.8804, -1.3404,\n",
      "          -0.0663,  0.4419, -0.4017, -0.0541,  1.4691,  0.1206, -0.0758,\n",
      "          -1.0911, -0.8314,  0.4901,  1.5731,  1.8342, -0.2396,  1.1685,\n",
      "          -1.1630,  0.3605,  0.5342],\n",
      "         [-1.6924,  0.5411, -0.8781, -1.1846,  0.9520, -0.9423,  0.2954,\n",
      "          -1.5968,  0.3904, -1.0671, -1.5759,  1.8513, -0.1569, -0.0854,\n",
      "          -0.2150,  1.1965, -0.4941,  0.5172,  0.5981, -1.9683,  1.3670,\n",
      "           1.6421,  0.8900,  0.5063]],\n",
      "\n",
      "        [[ 0.5651,  3.4911, -0.9449, -0.8897, -1.7088, -0.1747, -0.1165,\n",
      "           0.2865, -0.9496,  0.9583, -1.1354,  1.3982, -0.5795, -0.3252,\n",
      "           1.0468,  0.1211,  0.2555, -0.4093,  0.0700, -0.5264,  1.0216,\n",
      "           0.2576, -0.3247,  1.4577],\n",
      "         [-1.2724, -0.4139,  1.8491,  0.4949, -0.5004, -0.8804, -1.3404,\n",
      "          -0.0663,  0.4419, -0.4017, -0.0541,  1.4691,  0.1206, -0.0758,\n",
      "          -1.0911, -0.8314,  0.4901,  1.5731,  1.8342, -0.2396,  1.1685,\n",
      "          -1.1630,  0.3605,  0.5342],\n",
      "         [-1.2724, -0.4139,  1.8491,  0.4949, -0.5004, -0.8804, -1.3404,\n",
      "          -0.0663,  0.4419, -0.4017, -0.0541,  1.4691,  0.1206, -0.0758,\n",
      "          -1.0911, -0.8314,  0.4901,  1.5731,  1.8342, -0.2396,  1.1685,\n",
      "          -1.1630,  0.3605,  0.5342],\n",
      "         [-1.6924,  0.5411, -0.8781, -1.1846,  0.9520, -0.9423,  0.2954,\n",
      "          -1.5968,  0.3904, -1.0671, -1.5759,  1.8513, -0.1569, -0.0854,\n",
      "          -0.2150,  1.1965, -0.4941,  0.5172,  0.5981, -1.9683,  1.3670,\n",
      "           1.6421,  0.8900,  0.5063]]], grad_fn=<EmbeddingBackward0>)\n",
      "bbb.shape=\n",
      "torch.Size([2, 4, 24])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedding层用于将一个输入内容转化为一个向量,对于相同的原始内容,转化后的结果也是相同的,例如,在上面的第二个tensor中,有两个`3`,在转换后的结果中,对应位置的向量是完全相同的.\n",
   "id": "5c5241cbbf1a1e53"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 位置编码\n",
    "\n",
    "原文中的位置编码是使用正余弦函数的位置编码,这里up主介绍了一个可学习的位置编码.\n",
    "\n",
    "关于为什么需要位置编码,需要到后面一些在理解.\n",
    "\n"
   ],
   "id": "bf8e099033bd4412"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:02:07.833126Z",
     "start_time": "2024-08-03T13:02:07.820579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = torch.tensor(\n",
    "    [\n",
    "        [1,2,3,4],\n",
    "        [2,3,3,4]\n",
    "    ]\n",
    ")\n",
    "a.shape"
   ],
   "id": "3e2f34b7941e625c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "位置编码的作用是让每一个向量得到对应的位置信息,也就是为上面的tensor数组的每一个第二维数据加上位置信息.\n",
   "id": "c718adc4ba0d05a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:03:51.837207Z",
     "start_time": "2024-08-03T13:03:51.817155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pos = torch.tensor([[0,1,2,3]])\n",
    "pos,pos.shape"
   ],
   "id": "f9f8a984a0bfeff1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1, 2, 3]]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "只需要第二个维度能对上,就可以对两个变量进行相加.\n",
    "\n",
    "但是这里不会直接相加,而是先通过Embedding层进行词嵌入.\n"
   ],
   "id": "e3371bb86692b920"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:05:15.287555Z",
     "start_time": "2024-08-03T13:05:15.274653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 词嵌入\n",
    "word_ebd = ebd(a)\n",
    "word_ebd.shape\n"
   ],
   "id": "6654b08ccb72d7fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 24])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-03T13:06:00.895983Z",
     "start_time": "2024-08-03T13:06:00.883457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 位置编码\n",
    "ebd2 = nn.Embedding(4, 24)\n",
    "pos_ebd = ebd2(pos)\n",
    "pos_ebd.shape"
   ],
   "id": "9efab4435ec36608",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 24])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 多头注意力机制\n",
    "\n"
   ],
   "id": "f67ac8da0f1adfa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4986db75ae05e712"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
